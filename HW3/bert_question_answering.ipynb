{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad3473-1d41-466c-b8a9-9904d93fedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "def read_dataset(path):\n",
    "    with open(path, 'r') as f:\n",
    "        squad_dict = json.load(f)\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                # for answer in qa['answers']:\n",
    "                answer = qa['answers'][0]\n",
    "                answer_text = answer['text']\n",
    "                start_idx = answer['answer_start']\n",
    "                end_idx = start_idx + len(answer_text)\n",
    "                if context[start_idx:end_idx] == answer_text:\n",
    "                    answer['answer_end'] = end_idx\n",
    "                else:\n",
    "                    for n in [1, 2]:\n",
    "                        if context[start_idx-n:end_idx-n] == answer_text:\n",
    "                            answer['answer_start'] = start_idx - n\n",
    "                            answer['answer_end'] = end_idx - n\n",
    "                contexts.append(context)\n",
    "                questions.append(question)\n",
    "                answers.append(answer)\n",
    "                \n",
    "    return contexts, questions, answers\n",
    "\n",
    "train_contexts, train_questions, train_answers = read_dataset('spoken_train-v1.1.json')\n",
    "test_contexts, test_questions, test_answers = read_dataset('spoken_test-v1.1.json')\n",
    "\n",
    "\n",
    "# tokenize contexts and questions\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rein5/bert-base-uncased-finetuned-spoken-squad\")\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)\n",
    "\n",
    "\n",
    "# Encode and add token positions\n",
    "def encode_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
    "\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        shift = 1\n",
    "        while end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n",
    "            shift += 1\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "encode_token_positions(train_encodings, train_answers)\n",
    "encode_token_positions(test_encodings, test_answers)\n",
    "\n",
    "\n",
    "class ProcessDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# build datasets for training and testing \n",
    "train_dataset = ProcessDataset(train_encodings)\n",
    "test_dataset = ProcessDataset(test_encodings)\n",
    "\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"rein5/bert-base-uncased-finetuned-spoken-squad\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Training of model\n",
    "def train_model(train_loader, optimizer, max_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        loop = tqdm(train_loader, leave=True)\n",
    "        for batch in loop:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loop.set_description(f'Epoch {epoch}')\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-6)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "train_model(train_loader, optimizer, max_epochs=1)\n",
    "\n",
    "\n",
    "\n",
    "# Testing of model\n",
    "def test_model(test_loader):\n",
    "    model.eval()\n",
    "    accuraccies = []\n",
    "    loop = tqdm(test_loader)\n",
    "    answers = []\n",
    "    references = []\n",
    "    for batch in loop:\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            actual_start_positions = batch['start_positions'].to(device)\n",
    "            actual_end_positions = batch['end_positions'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predicted_start_positions = torch.argmax(outputs['start_logits'], dim=1)\n",
    "            predicted_end_positions = torch.argmax(outputs['end_logits'], dim=1)\n",
    "            accuraccies.append(((predicted_start_positions == actual_start_positions).sum()/len(actual_start_positions)).item())\n",
    "            accuraccies.append(((predicted_end_positions == actual_end_positions).sum()/len(predicted_end_positions)).item())\n",
    "            for i in range(predicted_start_positions.shape[0]):\n",
    "                all_tokens = tokenizer.convert_ids_to_tokens(batch['input_ids'][i])\n",
    "                answer = ' '.join(all_tokens[predicted_start_positions[i] : predicted_end_positions[i]+1])\n",
    "                ref = ' '.join(all_tokens[actual_start_positions[i] : actual_end_positions[i]+1])\n",
    "                ans_ids = tokenizer.convert_tokens_to_ids(answer.split())\n",
    "                answer = tokenizer.decode(ans_ids)\n",
    "                answers.append(answer)\n",
    "                references.append(ref)\n",
    "    return answers, references\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "answers, references = test_model(test_loader)\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "    if len(scores_for_ground_truths)==0: return 0\n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def evaluate(gold_answers, predictions):\n",
    "    f1 = exact_match = total = 0\n",
    "    for ground_truths, prediction in zip(gold_answers, predictions):\n",
    "        total += 1\n",
    "        exact_match += metric_max_over_ground_truths(exact_match_score, prediction, ground_truths)\n",
    "        f1 += metric_max_over_ground_truths(f1_score, prediction, [ground_truths])\n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "    return {'f1': f1}\n",
    "\n",
    "\n",
    "evaluate(references,answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
